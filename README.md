# Adaline - Porta LÃ³gica OU (One-Hot Encoding)

Este projeto implementa o algoritmo **Adaline (Adaptive Linear Neuron)** para aprender o comportamento da **porta lÃ³gica OU**, utilizando **representaÃ§Ã£o bipolar** e **codificaÃ§Ã£o One-Hot** para as classes.

O treinamento Ã© realizado por meio da **Regra Delta**, e a convergÃªncia do erro Ã© visualizada graficamente ao longo dos ciclos (Ã©pocas).

---

## ğŸ“Œ Objetivo

Demonstrar o funcionamento do algoritmo Adaline aplicado a um problema clÃ¡ssico de classificaÃ§Ã£o, explorando:

- Entradas bipolares (-1 e 1)
- SaÃ­das em One-Hot Encoding
- Aprendizado supervisionado
- ConvergÃªncia do erro quadrÃ¡tico

---

## ğŸ§  DescriÃ§Ã£o do Modelo

- **Entradas:** Dois neurÃ´nios (A e B)
- **SaÃ­das:** Duas classes (Verdadeiro e Falso) em One-Hot
- **FunÃ§Ã£o de ativaÃ§Ã£o:** Degrau bipolar
- **Algoritmo de aprendizado:** Regra Delta (Adaline)
- **CritÃ©rio de parada:** Erro total menor que uma tolerÃ¢ncia definida

---

## ğŸ“‚ Estrutura dos Dados

### Entradas (x)
RepresentaÃ§Ã£o bipolar da porta lÃ³gica OU:

| A  | B  |
|----|----|
|  1 |  1 |
|  1 | -1 |
| -1 |  1 |
| -1 | -1 |

### SaÃ­das (t)
CodificaÃ§Ã£o One-Hot:

- Verdadeiro â†’ `[1, -1]`
- Falso â†’ `[-1, 1]`

---

## âš™ï¸ ParÃ¢metros do Treinamento

- Taxa de aprendizado (`Î±`): `0.01`
- Limiar: `0.0`
- TolerÃ¢ncia do erro: `0.5`
- Pesos e bias inicializados aleatoriamente

---

## ğŸ“ˆ VisualizaÃ§Ã£o

Ao final do treinamento, Ã© exibido um grÃ¡fico mostrando a **convergÃªncia do erro quadrÃ¡tico total** ao longo dos ciclos.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- Python 3
- NumPy
- Matplotlib

---

## â–¶ï¸ Como Executar

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/seu-repositorio.git
